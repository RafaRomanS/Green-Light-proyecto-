{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99123b07",
   "metadata": {},
   "source": [
    "# Objetivo del notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b302161e",
   "metadata": {},
   "source": [
    "El objetivo de este notebook es desarrollar todas las funciones que creamos en nuestro archivo funciones.py y explicar que conseguimos con ellas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71655bfa",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf1c510",
   "metadata": {},
   "source": [
    "### Función transformación de \"df_electricity\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4905de7e",
   "metadata": {},
   "source": [
    "La funcion es:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40af09a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def electricity_transformation(df):\n",
    "    \n",
    "    # Crear nuevas columnas 'hour' y 'day'\n",
    "    df['datetime'] = pd.to_datetime(df['forecast_date'])\n",
    "    df['hour'] = df['datetime'].dt.hour\n",
    "    df['date'] = df['datetime'].dt.date\n",
    "\n",
    "    # Calcular la media por día y asignarla a la columna 'price_per_day'\n",
    "    df[\"price_per_day\"] = df.groupby('date')['euros_per_mwh'].transform(\"mean\")\n",
    "\n",
    "    # Calcular la diferencia de precio con respecto al valor anterior\n",
    "    df[\"price_diff_with_previous\"] = df[\"euros_per_mwh\"].diff()\n",
    "\n",
    "    # Crear columnas para los precios anteriores con shift\n",
    "    df['previous_price_t-hour'] = df['euros_per_mwh'].shift(1) # 1 hora\n",
    "    df['previous_price_t-day'] = df['euros_per_mwh'].shift(24) # 1 dia\n",
    "    df['previous_price_t-week'] = df['euros_per_mwh'].shift(168) # 1 semana\n",
    "    df['previous_price_t-month'] = df['euros_per_mwh'].shift(720) #  1 mes\n",
    "    \n",
    "    # Eliminamos la columna\n",
    "    df.drop(columns=['forecast_date'], inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0063a1d",
   "metadata": {},
   "source": [
    "- Creamos la variable \"datetime\" a partir de la variable \"forecast_date\" con formato fecha-hora\" lo cual nos va ayudar a unir con la tabla df_train en un futuro\n",
    "- Extraemos la hora y la fecha por separado en dos columnas diferentes\n",
    "- Calculamos la media del precio de la electricidad para cada dia y lo agregamos a una nueva columna\n",
    "- Creamos una nueva columna en la que calculamos la diferencia de precio con la hora anterior, esto nos sirve para ver las tendencias de precio\n",
    "- Creamos nuevas columnas con el precio de la hora anterior, día, semana y mes\n",
    "- Por ultimo eliminamos la colum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9674c13",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386c7864",
   "metadata": {},
   "source": [
    "### Función transformación de \"df_gas\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91301ce",
   "metadata": {},
   "source": [
    "La función es:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11e2b9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gas_transformation(df):\n",
    "    \n",
    "    # Pasamos a formato fecha para poder unir\n",
    "    df['date'] = pd.to_datetime(df['forecast_date'])\n",
    "    \n",
    "    # Creamos la columna average price \n",
    "    df['average_price'] = df[['lowest_price_per_mwh' , 'highest_price_per_mwh']].mean(axis=1)\n",
    "    \n",
    "    # Creamos la columna price_difference\n",
    "    df['price_difference'] = df['highest_price_per_mwh'] - df['lowest_price_per_mwh']\n",
    "    \n",
    "    # Eliminamos la columna\n",
    "    df.drop(columns=['forecast_date'], inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c36c3a8",
   "metadata": {},
   "source": [
    "- En este caso \"forecast_date\" solo nos indica la fecha y no la hora, por lo que la usamos para crear la variable \"date\"\n",
    "- Calculamos la media del precio para cada día y lo agregamos a una nueva columna\n",
    "- También creamos una columna con la diferencia entre el precio máximo y mínimo\n",
    "- Finalmente eliminamos la columna \"forecast_date\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ba52c2",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640c7cd9",
   "metadata": {},
   "source": [
    "### Función transformacion de \"df_client\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f529a0b6",
   "metadata": {},
   "source": [
    "La función es:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68282423",
   "metadata": {},
   "outputs": [],
   "source": [
    "def client_transformation(df):\n",
    "    \n",
    "    # Convertimos a formato fecha\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    \n",
    "    # Proporción de la capacidad instalada con respecto al total\n",
    "    df['capacity_ratio'] = df['installed_capacity'] / df.groupby('date')['installed_capacity'].transform('sum')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3e796e",
   "metadata": {},
   "source": [
    "- Convertimos a formato fecha la columna \"date\"\n",
    "- Calculamos la capacidad instalada con respecto al total, agrupando en este caso por día"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5addfc",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dad7dc1",
   "metadata": {},
   "source": [
    "### Función transformacion de \"df_train\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa12ddc",
   "metadata": {},
   "source": [
    "La función es:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "061b12d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_transformation(df, holiday):\n",
    "    \n",
    "    # Formato fecha-hora\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "    \n",
    "    # Crear nuevas columnas derivadas\n",
    "    df['date'] = df['datetime'].dt.date\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['year'] = df['datetime'].dt.year # año\n",
    "    df['month'] = df['datetime'].dt.month # mes\n",
    "    df['hour'] = df['datetime'].dt.hour # hora\n",
    "    df['day_of_month'] = df['datetime'].dt.day # dia del mes\n",
    "    df['day_of_week'] = df['datetime'].dt.day_of_week # dia de la semana\n",
    "    \n",
    "    # Creamos la columna que indica si es festivo o no\n",
    "    df['holiday'] =  df['date'].isin(holiday).astype(int)\n",
    "    \n",
    "    # Lagged-target\n",
    "    df['lagged_target_1day'] = df.groupby(['prediction_unit_id', 'is_consumption'])['target'].shift(24) # 1 dia\n",
    "    df['lagged_target_2day'] = df.groupby(['prediction_unit_id', 'is_consumption'])['target'].shift(48) # 2 dias\n",
    "    df['lagged_target_3day'] = df.groupby(['prediction_unit_id', 'is_consumption'])['target'].shift(72) # 3 dias\n",
    "    df['lagged_target_4day'] = df.groupby(['prediction_unit_id', 'is_consumption'])['target'].shift(96) # 4 dias\n",
    "    df['lagged_target_5day'] = df.groupby(['prediction_unit_id', 'is_consumption'])['target'].shift(120) # 5 dias\n",
    "    df['lagged_target_6day'] = df.groupby(['prediction_unit_id', 'is_consumption'])['target'].shift(144) # 6 dias\n",
    "    df['lagged_target_7day'] = df.groupby(['prediction_unit_id', 'is_consumption'])['target'].shift(168) # 7 dias\n",
    "    df['lagged_target_15day'] = df.groupby(['prediction_unit_id', 'is_consumption'])['target'].shift(360) # 15 dias\n",
    "    df['lagged_target_1month'] = df.groupby(['prediction_unit_id', 'is_consumption'])['target'].shift(720) # 30 dias\n",
    "    \n",
    "    # Tendencia\n",
    "    df['target_trend'] = df['lagged_target_2day'] - df['lagged_target_1day']\n",
    "    df['target_ratio'] = np.where(df['lagged_target_1day'] != 0, (df['lagged_target_2day'] - df['lagged_target_1day']) / df['lagged_target_1day'], np.nan)\n",
    "    df['target_diff_seasonal'] = df['lagged_target_7day'] - df['lagged_target_1day']\n",
    "    \n",
    "    # Columnas que indican si es findesemana o no\n",
    "    df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(bool)\n",
    "    df['is_working_day'] = ~df['is_weekend'].astype(bool)\n",
    "    \n",
    "    # Agrega columnas de funciones seno y coseno para la fecha y hora\n",
    "    df['sin_datetime'] = np.sin(2 * np.pi * df['datetime'].dt.dayofyear / 365)\n",
    "    df['cos_datetime'] = np.cos(2 * np.pi * df['datetime'].dt.dayofyear / 365)\n",
    "    \n",
    "    # Eliminamos esta columna ya que no nos aporta valor\n",
    "    df.drop(columns=['day_of_week'], inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3aa0970",
   "metadata": {},
   "source": [
    "- Convertimos a formato fecha-hora la columna \"datetime\"\n",
    "- A partir de dicha columna sacamos las siguientes:\n",
    "    - Fecha (la cual pasamos a formato fecha)\n",
    "    - Año\n",
    "    - Mes\n",
    "    - Hora\n",
    "    - Día del mes\n",
    "    - Día de la semana\n",
    "- Creamos una columna booleana que indica si es festivo o no (para ello necesita un listado con la fecha de los dias festivos, lo cual obtendremos mediante web-scrapping con otra función)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1066fee3",
   "metadata": {},
   "source": [
    "Consideramos que la producción de las dias anteriores sería bastante util para predecir los días siguientes, pero teniamos dos inconvenientes:\n",
    "- Hay tipos de clientes con características distintas\n",
    "- La variable \"target\" refleja tanto consumo como producción, dependiendo de la variable \"is_consumption\"\n",
    "\n",
    "Por ello agrupamos por \"predict_unit_id\", ya que cada valor de dicha columna agrupa a clientes con las mismas características y también agrupamos por \"is_consumption\" para que si se trataba de producción buscara un dato anterior también de producción\n",
    "\n",
    "Con esto conseguimos crear las siguientes columnas:\n",
    "- target de las siguientes fechas anteriores:\n",
    "    - 1 día\n",
    "    - 2 días\n",
    "    - 3 días\n",
    "    - 4 días\n",
    "    - 5 días\n",
    "    - 6 días\n",
    "    - 7 días\n",
    "    - 15 días\n",
    "    - 30 días\n",
    "\n",
    "Usando dichas columnas creamos las siguientes:\n",
    "- Tendencia, restando los dos dias anteriores\n",
    "- Ratio de cambio entre las columna \"lagged_target_2day\" y lagged_target_1day\" siempre y cuando este ultimo no sea 0, en ese caso se añadirá un valor nulo\n",
    "- Diferencia entre el target de hace 7 días y el de hace 1 día"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8aa088",
   "metadata": {},
   "source": [
    "A partir de la columna \"day_of_week\" creamos dos columnas:\n",
    "- Fin de semana\n",
    "- Día de trabajo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b083d089",
   "metadata": {},
   "source": [
    "Preveiamos que habría cierta estacionalidad en los datos, por lo que creamos las dos siguientes columnas:\n",
    "- Seno de la fecha\n",
    "- Coseno de la fecha\n",
    "\n",
    "Ambas representan la variación cíclica a lo largo del tiempo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9513d321",
   "metadata": {},
   "source": [
    "Finalmente eliminamos la columna \"day_of_week\" la cual solo creamos para poder obtener los dias de trabajo y fin de semana"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae4a471",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d210568",
   "metadata": {},
   "source": [
    "### Función transformación de \"df_historical\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbeca8c",
   "metadata": {},
   "source": [
    "La función es:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76a422a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def historical_transformation(df, df_location):\n",
    "    \n",
    "    # Guardamos estas columnas para usar despues\n",
    "    dates = df['datetime']\n",
    "    latitude = df['latitude']\n",
    "    longitude = df['longitude'] \n",
    "    \n",
    "    # Borramos las columnas que no aportan valor\n",
    "    columas_elim = ['latitude', 'longitude', 'data_block_id', 'datetime','rain', 'snowfall', 'winddirection_10m', 'windspeed_10m', 'cloudcover_high', 'cloudcover_mid']\n",
    "    df = df.drop(columns = columas_elim, axis=1)\n",
    "    \n",
    "    # Scaler\n",
    "    scaler = StandardScaler().fit(df)\n",
    "    dt = scaler.transform(df)\n",
    "    df_historical_scaled = pd.DataFrame(dt, columns=df.columns)\n",
    "    \n",
    "    # Aplicamos pca de 4, despues de estudiar cual es el mejor numero de componentes\n",
    "    pca = PCA(n_components=4, random_state = 42) \n",
    "    pca = pca.fit(df_historical_scaled)\n",
    "    df_historical_transformed = pca.transform(df_historical_scaled)\n",
    "    \n",
    "    # Utilizamos este número de clusters porque son los más adecuados, despues de realizar un estudio\n",
    "    kmeans = KMeans(n_clusters=4, n_init = \"auto\")\n",
    "    kmeans_labels = kmeans.fit(df_historical_transformed)\n",
    "    kmeans.fit(df_historical_transformed)\n",
    "    labels = kmeans.predict(df_historical_transformed)\n",
    "\n",
    "    # Agregar los clústers al DataFrame original\n",
    "    df['labels'] = labels\n",
    "    \n",
    "    # Utilizamos este número de clusters porque son los más adecuados, despues de realizar un estudio, para lograr un Kmeans mas especifico\n",
    "    kmeans = KMeans(n_clusters=10, n_init = 'auto')\n",
    "    kmeans_labels = kmeans.fit(df_historical_transformed)\n",
    "    kmeans.fit(df_historical_transformed)\n",
    "    specific_labels = kmeans.predict(df_historical_transformed)\n",
    "\n",
    "    # Agregar los clústers al DataFrame original\n",
    "    df['specific_labels'] = specific_labels\n",
    "\n",
    "    # Agregamos la columna datetime al DataFrame original\n",
    "    df['datetime'] = dates\n",
    "    df['latitude'] = latitude\n",
    "    df['longitude'] = longitude\n",
    "    \n",
    "    # Unimos con la tabla df_location para agregar la columna \"county\"\n",
    "    df = pd.merge(df, df_location, how='left', on=['longitude', 'latitude']) \n",
    "    \n",
    "    # Creamos una columna que diferencie temperaturas\n",
    "    df['temperature_dewpoint_diff_hist'] = df['temperature'] - df['dewpoint']\n",
    "    \n",
    "    # Radiación solar total ajustada por la cobertura de nubes\n",
    "    df['adjusted_solar_radiation'] = df['shortwave_radiation'] * (1 - df['cloudcover_total'])\n",
    "    \n",
    "    # Relación entre la temperatura y la presión atmosférica\n",
    "    df['temperature_pressure_ratio'] = df['temperature'] / df['surface_pressure']\n",
    "    \n",
    "    # Sacamos la hora, el dia y el mes para poder obtener variables segun la hora, el dia y el mes para cada region\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "    df['hour'] = df['datetime'].dt.hour\n",
    "    df['day'] = df['datetime'].dt.day_of_year\n",
    "    df['month'] = df['datetime'].dt.month\n",
    "    \n",
    "    # Creamos una columna de temperatura media por hora, dia y mes para cada region\n",
    "    df['temperature_per_hour_hist'] = df.groupby(['hour', 'county'])['temperature'].transform(lambda x: x.expanding().mean())\n",
    "    df['temperature_per_day_hist'] = df.groupby(['day', 'county'])['temperature'].transform(lambda x: x.expanding().mean())\n",
    "    df['temperature_per_month_hist'] = df.groupby(['month', 'county'])['temperature'].transform(lambda x: x.expanding().mean())\n",
    "    \n",
    "    # Creamos una columna con la nubosidad, por hora, dia y mes para cada region\n",
    "    df['cloudcover_total_per_hour'] = df.groupby(['hour', 'county'])['cloudcover_total'].transform(lambda x: x.expanding().mean())\n",
    "    df['cloudcover_total_per_day'] = df.groupby(['day', 'county'])['cloudcover_total'].transform(lambda x: x.expanding().mean())\n",
    "    df['cloudcover_total_per_month'] = df.groupby(['month', 'county'])['cloudcover_total'].transform(lambda x: x.expanding().mean())\n",
    "    \n",
    "    # Creamos una columna con la shortwave, por hora, dia y mes para cada region\n",
    "    df['shortwave_rad_per_hour'] = df.groupby(['hour', 'county'])['shortwave_radiation'].transform(lambda x: x.expanding().mean())\n",
    "    df['shortwave_rad_per_day'] = df.groupby(['day', 'county'])['shortwave_radiation'].transform(lambda x: x.expanding().mean())\n",
    "    df['shortwave_rad_per_month'] = df.groupby(['month', 'county'])['shortwave_radiation'].transform(lambda x: x.expanding().mean())\n",
    "    \n",
    "    # Creamos una columna con la radiacion directa, por hora, dia y mes para cada region\n",
    "    df['direct_solar_rad_per_hour_hist'] = df.groupby(['hour', 'county'])['direct_solar_radiation'].transform(lambda x: x.expanding().mean())\n",
    "    df['direct_solar_rad_per_day_hist'] = df.groupby(['day', 'county'])['direct_solar_radiation'].transform(lambda x: x.expanding().mean())\n",
    "    df['direct_solar_rad_per_month_hist'] = df.groupby(['month', 'county'])['direct_solar_radiation'].transform(lambda x: x.expanding().mean())\n",
    "    \n",
    "    # Creamos una lista con las columnas a las que hacerle la media\n",
    "    col_mean = [col for col in df.columns if col not in ['labels', 'specific_labels', 'datetime', 'county']]\n",
    "    \n",
    "    # Hacemos la media de las columnas por county y en la columna de \"labels\" utilizamos la moda\n",
    "    df = df.groupby(['datetime', 'county']).agg({'labels': lambda x: x.mode().iloc[0], \n",
    "                                                 'specific_labels': lambda x: x.mode().iloc[0],\n",
    "                                                 **{col: 'mean' for col in col_mean}}).reset_index()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef00e107",
   "metadata": {},
   "source": [
    "Al igual que en la funcion de \"train_transformation\" queriamos acceder a los valores de \"target\" de fechas anteriores de clientes similares, queriamos hacer lo mismo, pero además añadiendole que en ese momento existieran unas condiciones climatológicas similares, para ello tuvimos que hacer lo siguiente:\n",
    "- Teniamos que hacer agrupaciones de las variables climatológicas, y decidimos usar KMeans para lograrlo, por lo que necesitamos realizar lo siguiente:\n",
    "    - Guardar las columnas: \"datetime\", \"latitude\" y \"longitude\" ya que ahora las teniamos que eliminar pero posteriormente nos haría falta\n",
    "    - Eliminamos las columnas que no nos aportaban valor al KMeans\n",
    "    - Realizamos PCA para reducir la dimensionalidad (anteriormente hicimos un estudio para ver el mejor numero de componentes)\n",
    "\n",
    "Antes de ejecutar KMeans vimos cuales eran las mejores opciones para el número de clusters, la mejor opción era 2 (la cual descartamos ya que simplemente diferenciaría entre día y noche y queriamos algo más específico), seguido de 10 y 4\n",
    "\n",
    "El problema era que si poníamos 10 se volvia tan especifico que cuando queriamos laggear varias veces generaba muchos nulos, ya que le costaba mucho encontrar datos anteriores\n",
    "\n",
    "Finalmente decidimos crear 2 columnas:\n",
    "- Cluster de 4, sobre la que laggearemos varias veces\n",
    "- Cluster de 10, sobre el que solo laggearemos una vez"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d19c38",
   "metadata": {},
   "source": [
    "- Volvemos a agregar las columnas que habiamos guardado anteriormente\n",
    "- Unimos con la tabla \"df_location\" para obtener la columna \"county\"\n",
    "- Creamos una variable sobre la diferencia entre \"temperature\" y \"dew_point\", ya que son dos variables relacionadas con la temperatura\n",
    "- Radiación en relación a la nubosidad\n",
    "- Relación temperatura y presión atmosférica\n",
    "- Convertir a formato fecha-hora la columna \"datetime\" y sacamos de ahí las siguientes columnas:\n",
    "    - Hora\n",
    "    - Día\n",
    "    - Mes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c257163",
   "metadata": {},
   "source": [
    "Ahora queriamos crear nuevas columnas con la media por hora, dia y mes, pero solo con los datos hasta ese momento, no los futuros, por lo que tuvimos que hacer medias rodantes de las siguientes variables:\n",
    "- Temperatura\n",
    "- Nubosidad total\n",
    "- Radiación de ondas cortas\n",
    "- Radiación total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1cc00f",
   "metadata": {},
   "source": [
    "Finalmente tuvimos otro problema, al estar los datos por longitud y latitud, teniamos diferentes filas para una misma fecha-hora en un mismo county, y solo podiamos tener una fila para cada fecha-hora y county, ya que de esa manera estaban estructurados los datos en \"df_train\" donde teniamos nuestra variable objetivo\n",
    "\n",
    "Entonces teniamos que como transformar esos datos y para ello hicimos lo siguiente:\n",
    "- Agrupamos por fecha-hora y county\n",
    "- Hicimos la moda para \"labels\" y \"specific_labels\", ya que estas columnas realmente eran de tipo objeto y las necesitabamos para laggear más adelante\n",
    "- Hicimos la media para el resto de variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa9eaa2",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6eb0142",
   "metadata": {},
   "source": [
    "### Función para obtener los días festivos de Estonia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c462636",
   "metadata": {},
   "source": [
    "La función es:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d211cfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_holiday(year):\n",
    "\n",
    "    url = f'https://www.timeanddate.com/holidays/estonia/{year}?hol=1' # entramos en la pagina web segun el año\n",
    "\n",
    "    response = requests.get(url)\n",
    "    bool(response)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    x = soup.find('section', attrs={'class': 'table-data__table'})\n",
    "    \n",
    "    fechas = [] # creamos lista donde almacenaremos las fechas\n",
    "\n",
    "    for f in x.find_all('tr', attrs={'class': 'showrow'}):\n",
    "        fecha = f.find('th', attrs={'class':'nw'}).text # obtenemos el mes y dia de la pagina web\n",
    "        fecha = fecha + ' ' + str(year) # añadimos el año a la fecha\n",
    "        fecha = replace_month(fecha) # utilizamos función para reemplazar el nombre del mes\n",
    "        fecha = datetime.strptime(fecha, '%d %b %Y') # convertimos a formato fecha\n",
    "        fecha = fecha.strftime('%Y-%m-%d') # modificamos al formato fecha ingles\n",
    "        fechas.append(fecha) # lo agregamos a la lista\n",
    "        \n",
    "    return fechas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85dac253",
   "metadata": {},
   "source": [
    "En este codigo accedemos a una web que nos indica la fecha de los festivos en Estonia, lo cual obtenemos mediante web-scrapping, el problema vino a raiz de que la fecha nos la aportaba en formato español, el cual suponia un problema a la hora de convertirlo a formato fecha ya que no lo identificaba y es por esto que creamos la función \"replace_month\" la cual nos permite modificar los datos para poder convertirlo a formato fecha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d01706",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74c568f",
   "metadata": {},
   "source": [
    "### Función de reemplazo de meses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716caedd",
   "metadata": {},
   "source": [
    "La función es:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25870233",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_month(spanish_date):\n",
    "    months_translation = {\n",
    "        'ene': 'Jan',\n",
    "        'feb': 'Feb',\n",
    "        'mar': 'Mar',\n",
    "        'abr': 'Apr',\n",
    "        'may': 'May',\n",
    "        'jun': 'Jun',\n",
    "        'jul': 'Jul',\n",
    "        'ago': 'Aug',\n",
    "        'sep': 'Sep',\n",
    "        'oct': 'Oct',\n",
    "        'nov': 'Nov',\n",
    "        'dic': 'Dec'\n",
    "    }\n",
    "\n",
    "    # Reemplazar los nombres de los meses en español por sus equivalentes en inglés\n",
    "    for month_es, month_en in months_translation.items():\n",
    "        spanish_date = spanish_date.replace(f'de {month_es}', month_en)\n",
    "\n",
    "    return spanish_date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c276d2",
   "metadata": {},
   "source": [
    "Con esta función conseguimos modificar esos datos para que pueda interpretarlo como fecha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8f628f",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f955cb3",
   "metadata": {},
   "source": [
    "### Funcion transformación de \"df\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5961e9e5",
   "metadata": {},
   "source": [
    "La función es:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fea34411",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_transformation_total(df):\n",
    "    \n",
    "    # Lagged_target\n",
    "    df['lagged_target_by_weather_1'] = df.groupby(['prediction_unit_id', 'is_consumption', 'hour', 'labels'])['target'].shift(1)\n",
    "    df['lagged_target_by_weather_2'] = df.groupby(['prediction_unit_id', 'is_consumption', 'hour', 'labels'])['target'].shift(2) \n",
    "    df['lagged_target_by_weather_3'] = df.groupby(['prediction_unit_id', 'is_consumption', 'hour', 'labels'])['target'].shift(3)\n",
    "    \n",
    "    df['lagged_target_specific_weather'] = df.groupby(['prediction_unit_id', 'is_consumption', 'hour', 'specific_labels'])['target'].shift(1)\n",
    "    \n",
    "    # Creamos una nueva variable\n",
    "    df['rad_install_cap_relation'] = df['shortwave_radiation'] / df['installed_capacity']\n",
    "    \n",
    "    # Eliminamos las filas en las que hay nulos\n",
    "    df = df.dropna()\n",
    "    \n",
    "    # Eliminamos las columnas que no aportan valor\n",
    "    columnas_a_eliminar = ['datetime', 'data_block_id', 'prediction_unit_id', 'date']\n",
    "    df = df.drop(columnas_a_eliminar, axis=1)\n",
    "    \n",
    "    # Modificamos el tipo de datos de alguna de las variables\n",
    "    df['county'] = df['county'].astype('category')\n",
    "    df['product_type'] = df['product_type'].astype('category')\n",
    "    df['labels'] = df['labels'].astype('category')\n",
    "    df['specific_labels'] = df['specific_labels'].astype('category')\n",
    "    df['is_business'] = df['is_business'].astype(bool)\n",
    "    df['is_consumption'] = df['is_consumption'].astype(bool)\n",
    "    df['holiday'] = df['holiday'].astype(bool)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5afc28",
   "metadata": {},
   "source": [
    "Como ya hemos comentado antes queriamos obtener el \"target\" anterior de clientes con las mismas caracteristicas y diferenciando entre producir y consumir, pero ahora queriamos además que fuese la misma hora y que tuviera las mismas condiciones climáticas y ahora que ya habiamos unido las tablas podiamos hacerlo, añadiendo a la agrupación que hicimos en \"train_transformation\" las columnas: \"hour\" y \"labels\"\n",
    "\n",
    "En este caso laggeamos 3 veces, mientras que cuando agrupamos por \"specific_labels\" en lugar de \"labels\" solo laggeamos una vez, ya que generaba muchos nulos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96252c1",
   "metadata": {},
   "source": [
    "Aprovechando la union de las diferentes tablas creamos otra variable que relacionaba la radiación de ondas cortas con la capacidad instalada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07530e0c",
   "metadata": {},
   "source": [
    "Posteriormente eliminamos los nulos y las columnas que no aportan valor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8cac10",
   "metadata": {},
   "source": [
    "Y para finalizar modificamos el tipo de dato de las siguientes variables:\n",
    "- \"county\" (categórica)\n",
    "- \"product_type\" (categórica)\n",
    "- \"labels\" (categórica)\n",
    "- \"specific_labels\" (categórica)\n",
    "- \"is_business\" (booleana)\n",
    "- \"is_consumption\" (booleana)\n",
    "- \"holiday\" (booleana)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
